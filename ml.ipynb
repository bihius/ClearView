{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "gpuType": "V28"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FasterRCNN"
   ],
   "metadata": {
    "id": "TzIEmM1xcT3v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "# For measuring the inference time.\n",
    "import time"
   ],
   "metadata": {
    "id": "78jLX-GhSXRK",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:07:15.349128Z",
     "start_time": "2024-06-03T13:07:15.341197Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def download_and_resize_image(url, new_width=256, new_height=256,\n",
    "                              display=False):\n",
    "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
    "  response = urlopen(url)\n",
    "  image_data = response.read()\n",
    "  image_data = BytesIO(image_data)\n",
    "  pil_image = Image.open(image_data)\n",
    "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.LANCZOS)\n",
    "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
    "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
    "  return filename"
   ],
   "metadata": {
    "id": "x-YOsY4mSIBP",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:07:15.470310Z",
     "start_time": "2024-06-03T13:07:15.460304Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:09:00.570785Z",
     "start_time": "2024-06-03T13:08:19.778531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#module_handle = \"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\"\n",
    "#detector = hub.load(module_handle)\n",
    "#tf.saved_model.save(detector, \"./\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./assets\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T13:33:00.690288Z",
     "start_time": "2024-06-03T13:32:44.129183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
    "\n",
    "# detector = hub.load(module_handle).signatures['default']\n",
    "\n",
    "#module_handle = \"https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1\"\n",
    "#detector = hub.load(module_handle)\n",
    "#tf.saved_model.save(detector, \"./\")\n",
    "\n",
    "detector = tf.saved_model.load(\"./\")"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'default'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 9\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# detector = hub.load(module_handle).signatures['default']\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#detector = hub.load(module_handle)\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#tf.saved_model.save(detector, \"./\")\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m detector \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msaved_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignatures\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdefault\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/venv/lib/python3.11/site-packages/tensorflow/python/saved_model/signature_serialization.py:302\u001B[0m, in \u001B[0;36m_SignatureMap.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[0;32m--> 302\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_signatures\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'default'"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  return img\n"
   ],
   "metadata": {
    "id": "rMeqqeuqSl-p",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:15:38.342122Z",
     "start_time": "2024-06-03T13:15:38.337187Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def run_detector(detector, path, min_score=0.5):\n",
    "    img = load_img(path)\n",
    "\n",
    "    # Konwertuj obraz do uint8\n",
    "    converted_img = tf.image.convert_image_dtype(img, dtype=tf.uint8)[tf.newaxis, ...]\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = detector(input_tensor=converted_img)\n",
    "    end_time = time.time()\n",
    "\n",
    "    result = {key: value.numpy() for key, value in result.items()}\n",
    "\n",
    "    # Wypisanie wykrytych obiektów z uwzględnieniem progu pewności\n",
    "    for score, entity in zip(result[\"detection_scores\"][0], result[\"detection_classes\"][0]):\n",
    "        if score >= min_score:\n",
    "            print(f\"Object: {entity}, Score: {round(float(score), 2)}\")\n"
   ],
   "metadata": {
    "id": "nkZwV2wfSovh",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:15:40.567680Z",
     "start_time": "2024-06-03T13:15:40.555831Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def process_fasterrcnn(image_url):\n",
    "  start_time = time.time()\n",
    "  image_path = download_and_resize_image(image_url, 640, 480)\n",
    "  run_detector(detector, image_path)\n",
    "  end_time = time.time()\n",
    "  print(\"Inference time:\",round(end_time-start_time, 2))\n"
   ],
   "metadata": {
    "id": "eg3k5Po4TfVQ",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:15:42.440974Z",
     "start_time": "2024-06-03T13:15:42.432767Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detectron2\n"
   ],
   "metadata": {
    "id": "szWjRjQ6cFJn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !python -m pip install pyyaml==5.1\n",
    "# import sys, os, distutils.core\n",
    "# # Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
    "# # See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
    "# # !git clone 'https://github.com/facebookresearch/detectron2'\n",
    "# # dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "# # !python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "# # sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "# # Properly install detectron2. (Please do not install twice in both ways)\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git' \n",
    "\n",
    "#### MOVED TO INSTALL PACKAGES SECTION"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "t2ptBzYxcHy9",
    "outputId": "b3e1e992-f659-4511-a10a-31d8d082a8c4",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:15:45.598185Z",
     "start_time": "2024-06-03T13:15:45.591451Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import requests\n"
   ],
   "metadata": {
    "id": "rsMge63xhEsS",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:15:54.675894Z",
     "start_time": "2024-06-03T13:15:48.894631Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "def process_detectron2(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        image_data = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
    "        im = cv2.imdecode(image_data, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        cfg = get_cfg()\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "\n",
    "        # Ustawienie modelu do używania CPU\n",
    "        cfg.MODEL.DEVICE = \"cpu\"\n",
    "\n",
    "        predictor = DefaultPredictor(cfg)\n",
    "        outputs = predictor(im)\n",
    "\n",
    "        # Extract the classes of detected objects\n",
    "        instances = outputs[\"instances\"]\n",
    "        classes = instances.pred_classes\n",
    "        class_names = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes\n",
    "        detected_objects = [class_names[i] for i in classes]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(detected_objects)\n",
    "        print(\"Inference time:\", round(end_time - start_time, 2))"
   ],
   "metadata": {
    "id": "R7YvX3aLf6qe",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:52:52.551829Z",
     "start_time": "2024-06-03T13:52:52.541185Z"
    }
   },
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Images\n"
   ],
   "metadata": {
    "id": "ArkIATu3cq0z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "image_urls = [\n",
    "  \"https://images.unsplash.com/photo-1600716051809-e997e11a5d52\",\n",
    "  \"https://plus.unsplash.com/premium_photo-1661584150981-10626721db7a\",\n",
    "  \"https://images.unsplash.com/photo-1716117273853-75a1989029f2\"\n",
    "  ]"
   ],
   "metadata": {
    "id": "fRofqqFEdDAq",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:24:33.317531Z",
     "start_time": "2024-06-03T13:24:33.312714Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results\n"
   ],
   "metadata": {
    "id": "DArHlyHncuDx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for url in image_urls:\n",
    "  print(\"Image: \" + url)\n",
    "  #print(\"Faster RCNN:\")\n",
    "  #process_fasterrcnn(url)\n",
    "  print(\"Detectron 2:\")\n",
    "  process_detectron2(url)\n",
    "  print(\"CLIP:\")\n",
    "  process_clip(url)\n",
    "  print(\"\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "collapsed": true,
    "id": "6FJ-BBp_dJvI",
    "outputId": "eb9dc765-aed0-4f66-d509-467ac0613518",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:54:32.144803Z",
     "start_time": "2024-06-03T13:52:58.475639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: https://images.unsplash.com/photo-1600716051809-e997e11a5d52\n",
      "Detectron 2:\n",
      "\u001B[32m[06/03 15:53:02 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_a3ec72.pkl: 254MB [00:46, 5.50MB/s]                                                                                                                                                                    \n",
      "/home/bihius/venv/lib/python3.11/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orange', 'orange', 'dining table', 'knife']\n",
      "Inference time: 57.86\n",
      "CLIP:\n",
      "Wstawiono dane dla obrazu: photo-1600716051809-e997e11a5d52\n",
      "\n",
      "\n",
      "Image: https://plus.unsplash.com/premium_photo-1661584150981-10626721db7a\n",
      "Detectron 2:\n",
      "\u001B[32m[06/03 15:54:03 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n",
      "['person', 'bottle', 'mouse', 'book']\n",
      "Inference time: 10.35\n",
      "CLIP:\n",
      "Wstawiono dane dla obrazu: premium_photo-1661584150981-10626721db7a\n",
      "\n",
      "\n",
      "Image: https://images.unsplash.com/photo-1716117273853-75a1989029f2\n",
      "Detectron 2:\n",
      "\u001B[32m[06/03 15:54:19 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n",
      "['person', 'person', 'person', 'umbrella', 'person', 'bicycle', 'chair', 'person', 'person', 'chair', 'person', 'person', 'handbag', 'chair', 'umbrella', 'umbrella', 'umbrella', 'person', 'person', 'person', 'person', 'chair', 'umbrella', 'person', 'umbrella', 'person', 'handbag']\n",
      "Inference time: 10.57\n",
      "CLIP:\n",
      "Wstawiono dane dla obrazu: photo-1716117273853-75a1989029f2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CLIP\n"
   ],
   "metadata": {
    "id": "iUJiOmUI_Kya"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import hashlib\n",
    "\n",
    "# Inicjalizacja Supabase\n",
    "db_user = \"postgres\"\n",
    "db_password = \"your-super-secret-and-long-postgres-password\"  # Wstaw swoje hasło\n",
    "db_host = \"10.15.10.254\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"postgres\"\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=db_name,\n",
    "        user=db_user,\n",
    "        password=db_password,\n",
    "        host=db_host,\n",
    "        port=db_port\n",
    "    )\n",
    "    print(\"Połączono z bazą danych PostgreSQL\")\n",
    "except Exception as e:\n",
    "    print(f\"Nie udało się połączyć z bazą danych: {e}\")\n",
    "\n",
    "# Funkcja do tworzenia tabeli, jeśli jeszcze nie istnieje\n",
    "def create_table(conn):\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS image_features (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                image_name TEXT NOT NULL,\n",
    "                image_url TEXT NOT NULL,\n",
    "                image_hash TEXT NOT NULL,\n",
    "                image_feature FLOAT8[] NOT NULL\n",
    "            );\n",
    "            \"\"\")\n",
    "            conn.commit()\n",
    "            print(\"Tabela utworzona (jeśli jeszcze nie istniała)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Nie udało się utworzyć tabeli: {e}\")\n",
    "\n",
    "# Funkcja do wstawiania danych do tabeli\n",
    "def insert_image_feature(conn, image_name, image_url, image_hash, image_feature):\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO image_features (image_name, image_url, image_hash, image_feature)\n",
    "                VALUES (%s, %s, %s, %s);\n",
    "                \"\"\",\n",
    "                (image_name, image_url, image_hash, image_feature)\n",
    "            )\n",
    "            conn.commit()\n",
    "            print(f\"Wstawiono dane dla obrazu: {image_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Nie udało się wstawić danych: {e}\")\n",
    "\n",
    "# Funkcja do sprawdzania, czy obraz o podanym hashu już istnieje w bazie danych\n",
    "def image_exists(conn, image_hash):\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT EXISTS(SELECT 1 FROM image_features WHERE image_hash = %s);\n",
    "                \"\"\",\n",
    "                (image_hash,)\n",
    "            )\n",
    "            return cursor.fetchone()[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Nie udało się sprawdzić, czy obraz istnieje: {e}\")\n",
    "        return False\n",
    "\n",
    "# Funkcja do generowania hasha dla obrazu\n",
    "def generate_image_hash(image):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    for chunk in iter(lambda: image.read(4096), b\"\"):\n",
    "        hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "# Inicjalizacja modelu CLIP\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Pobieranie i przetwarzanie obrazów\n",
    "def process_clip(image_url):\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        image_name = image_url.split(\"/\")[-1]  # Wydobycie nazwy pliku z URL\n",
    "        image = Image.open(io.BytesIO(response.content))\n",
    "\n",
    "        # Generowanie hasha dla obrazu\n",
    "        image_hash = generate_image_hash(io.BytesIO(response.content))\n",
    "\n",
    "        # Sprawdzanie, czy obraz już istnieje w bazie danych\n",
    "        if image_exists(conn, image_hash):\n",
    "            print(f\"Obraz {image_name} już istnieje w bazie danych.\")\n",
    "            pass\n",
    "\n",
    "        image = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_feature = model.encode_image(image).cpu().numpy().tolist()\n",
    "\n",
    "        # Wstawianie wektora do bazy danych\n",
    "        insert_image_feature(conn, image_name, image_url, image_hash, image_feature)\n",
    "    except Exception as e:\n",
    "        print(f\"Nie udało się przetworzyć obrazu z URL: {image_url}, błąd: {e}\")\n",
    "\n",
    "# Tworzenie tabeli, jeśli jeszcze nie istnieje\n",
    "create_table(conn)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZ2Y0OKlAWWY",
    "outputId": "9fab6702-64c0-4333-b752-ab59dc2c3e93",
    "ExecuteTime": {
     "end_time": "2024-06-03T13:28:38.083200Z",
     "start_time": "2024-06-03T13:28:28.099208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Połączono z bazą danych PostgreSQL\n",
      "Tabela utworzona (jeśli jeszcze nie istniała)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def search_images(query, conn, model, device, top_k=5):\n",
    "    # Przetwórz zapytanie tekstowe na wektor cech za pomocą CLIP\n",
    "    text = clip.tokenize([query]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text).cpu().numpy()\n",
    "\n",
    "    # Pobierz wszystkie wektory cech obrazów z bazy danych\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(\"SELECT image_url, image_feature FROM image_features;\")\n",
    "            rows = cursor.fetchall()\n",
    "            image_urls = [row[0] for row in rows]\n",
    "            image_features = np.array([row[1] for row in rows])\n",
    "    except Exception as e:\n",
    "        print(f\"Nie udało się pobrać danych z bazy: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Oblicz podobieństwo między wektorem zapytania a wektorami cech obrazów\n",
    "    similarities = np.dot(image_features, text_features.T).squeeze()\n",
    "\n",
    "    # Znajdź top_k najbardziej podobnych obrazów\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    results = [(image_urls[i], similarities[i]) for i in top_indices]\n",
    "\n",
    "    return results\n",
    "\n",
    "# Przykładowe użycie\n",
    "\n",
    "pre_query = \"a photo of a \"\n",
    "user_query = \"umbrellas and tables\"\n",
    "final_query = str(pre_query+user_query)\n",
    "results = search_images(final_query, conn, model, device)\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "for img_url, score in results:\n",
    "    print(f\"Image URL: {img_url}, Similarity Score: {score:.4f}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WLFFKelELe9",
    "outputId": "2b2c51ab-28a8-46b2-fcdc-0fb5c729fa09"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Install packages"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install tensorflow tensorflow_hub matplotlib requests pillow psycopg2-binary opencv-python torch",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install git+https://github.com/openai/CLIP",
   "outputs": [],
   "execution_count": null
  }
 ]
}
